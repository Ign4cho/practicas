{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import gspread as gs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejecutar para crear un nuevo archivo en google drive la primera vez\n",
    "\n",
    "# sh = gc.create('documentos_procesado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo .xlsx\n",
    "file_path = \"revision_documentos.xlsx\"\n",
    "file_path_destino = \"revision_documentos_procesado_\" + datetime.now().strftime(\"%Y%m%d%H%M\") + \".xlsx\"\n",
    "credentials_filename='credenciales\\client_secret_290615798724-sg1nk4latali6a8akhe169r66gg7hmd8.apps.googleusercontent.com.json'\n",
    "# Lee el archivo Excel\n",
    "df = pd.read_excel(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n"
     ]
    }
   ],
   "source": [
    "# Para el primer analisis, se eliminan las columnas que no son relevantes\n",
    "# se eliminan las columnas: DOCUMENTOVIGENCIA, FECHA_INICIO_DOCUMENTO, FECHA_FIN_DOCUMENTO\n",
    "# DOCO_EMPR_RUT, TIPO, 'Hora extendida', 'Fecha y hora', 'Fecha.1', 'Gestionado','Tiempo desde ingreso', 'Tiempo para cumplir en plazo', 'Unnamed: 40', 'Unnamed: 41', 'Unnamed: 42', 'Unnamed: 43' 'Unnamed: 29','Unnamed: 30', 'Fecha', 'Hora', 'AM/PM'\n",
    "columnas_no_tenidas_en_cuenta = [\n",
    "    'DOCUMENTOVIGENCIA', 'FECHA_INICIO_DOCUMENTO', 'FECHA_FIN_DOCUMENTO', 'DOCO_EMPR_RUT',\n",
    "    'TIPO', 'Hora extendida', 'Fecha y hora', 'Fecha.1', 'Gestionado',\n",
    "     'Tiempo desde ingreso', 'Tiempo para cumplir en plazo', 'Unnamed: 40',\n",
    "     'Unnamed: 41', 'Unnamed: 42', 'Unnamed: 43', 'Unnamed: 29','Unnamed: 30',\n",
    "     'Fecha', 'Hora', 'AM/PM']\n",
    "\n",
    "df.drop(columnas_no_tenidas_en_cuenta,\n",
    "        axis=1, inplace=True)\n",
    "\n",
    "#verificamos cuantos usuarioregistroid son nulos\n",
    "print(df['USUARIOREGISTROID'].isnull().sum())\n",
    "\n",
    "#en la columna USUARIOREGISTROID, reemplazamos los valores nulos por -1\n",
    "df['USUARIOREGISTROID'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la columna tipo, en base a la columna estado. \n",
    "# Si el estado es \"Enviado\", el tipo es de \"Entrada\"\n",
    "# Si el estado es \"Rechazado\" o \"Validado\", el tipo es de \"Salida\"\n",
    "\n",
    "df[\"TIPO\"] = df[\"ESTADO\"].apply(lambda x: \"Entrada\" if x == \"Enviado\" else \"Salida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos la columna FECHA_REGISTRO_HH, en formato mm/dd/yyyy hh:mm:ss PM/AM a datetime\n",
    "df[\"FECHA_REGISTRO_HH\"] = pd.to_datetime(df[\"FECHA_REGISTRO_HH\"], format=\"%m/%d/%Y %I:%M:%S %p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos dos dataframes, uno con los documentos de entrada y otro con los de salida\n",
    "df_entrada = df[df[\"TIPO\"] == \"Entrada\"]\n",
    "df_salida = df[df[\"TIPO\"] == \"Salida\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28869, 25)\n",
      "(26718, 25)\n"
     ]
    }
   ],
   "source": [
    "print(df_entrada.shape)\n",
    "print(df_salida.shape)\n",
    "\n",
    "columnas_eliminadas_salida = ['FECHA_REGISTRO', 'ORIGENDOCID', 'ORIGEN',\n",
    "       'DOCO_TIDO_ID', 'ID_ESTADO',\n",
    "       'DOCUMENTOSITUACIONID', 'DOCUMENTOSITUCION', 'USUARIOREGISTRO',\n",
    "       'USUARIOREGISTROCUENTA', 'USUARIOREGISTRONOMBRE',\n",
    "       'DOCO_TIPO_VALIDACION', 'DOCO_CONT_ID', 'FECHA_INGRESO_DOCUMENTO'\n",
    "       , 'DOCUMENTOESPECIALIDADID', 'DOCUMENTOESPECIALIDAD',\n",
    "       'DOCUMENTOOCUPACIONID', 'DOCUMENTOOCUPACION',\n",
    "       'DOCUMENTOCERTOCUPACIONID', 'DOCUMENTOCERTOCUPACION', 'TIPO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dataframe de salidas, nos interesa conservar las columnas\n",
    "# FECHA_REGISTRO_HH, ESTADO, USUARIOREGISTROID, pero renombramos a \n",
    "# FECHA_SALIDA, ESTADO_SALIDA, USUARIOID_SALIDA  para luego poder hacer el merge\n",
    "df_salida = df_salida.rename(columns={\"FECHA_REGISTRO_HH\": \"FECHA_SALIDA\", \"ESTADO\": \"ESTADO_SALIDA\", \"USUARIOREGISTROID\": \"USUARIOID_SALIDA\"})\n",
    "df_salida.drop(\n",
    "       columnas_eliminadas_salida\n",
    "       , axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos el merge, en base al doco_id, lo hacemos de tipo left para conservar los documentos de entrada\n",
    "df_merged = pd.merge(df_entrada, df_salida, on=\"DOCO_ID\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código de abajo es para ver si hay documentos que tienen salida pero no entrada, que en teoría no debería ocurrir\n",
    "Una de las causas puede ser que la entrada este en otro documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos el merge de tipo right para conservar todos los documentos de salida\n",
    "df_right_merged = pd.merge(df_entrada, df_salida, on=\"DOCO_ID\", how=\"right\")\n",
    "\n",
    "# Filtramos los registros donde ID_ESTADO de entrada sea NaN\n",
    "df_salida_sin_entrada = df_right_merged[df_right_merged['ID_ESTADO'].isna()]\n",
    "\n",
    "# Mostramos los documentos de salida que no tienen un documento de entrada correspondiente\n",
    "# print(df_salida_sin_entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregamos una columna con la diferencia de tiempo entre entrada y salida de los documentos en horas \n",
    "# en caso de no haber fecha salida, la columna se rrrellena con NaN\n",
    "# en caso de no haber fecha de registro, la columna se rellena con NaN\n",
    "\n",
    "df_merged[\"DIFERENCIA_HORAS\"] = df_merged.apply(\n",
    "    lambda row: (row[\"FECHA_SALIDA\"] - row[\"FECHA_REGISTRO_HH\"]).total_seconds() / 3600\n",
    "    if pd.notnull(row[\"FECHA_SALIDA\"]) and pd.notnull(row[\"FECHA_REGISTRO_HH\"]) else np.nan,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el umbral de 48 horas\n",
    "umbral = 48\n",
    "\n",
    "# Agregamos un campo de desviación respecto al umbral\n",
    "df_merged[\"DESVIACION\"] = df_merged[\"DIFERENCIA_HORAS\"] - umbral\n",
    "\n",
    "# Determinamos el estado, teniendo en cuenta la desviación y los documentos\n",
    "# sin salida\n",
    "\n",
    "df_merged['estado'] = df_merged.apply(\n",
    "    lambda row: 'Sin gestionar' if pd.isna(row['FECHA_SALIDA'])\n",
    "    else 'Sin entrada' if pd.isna(row['FECHA_REGISTRO_HH'])\n",
    "    else 'Fuera de plazo' if row['DESVIACION'] > 0\n",
    "    else 'En plazo' if row['DESVIACION'] < 0\n",
    "    else 'Igual', \n",
    "    axis=1\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mes actual y los tres meses anteriores\n",
    "hoy = datetime.now()\n",
    "mes_actual = hoy.month\n",
    "año_actual = hoy.year\n",
    "\n",
    "# Crear una lista de los tres meses anteriores y el mes actual\n",
    "meses_validos = [(mes_actual - i - 1) % 12 + 1 for i in range(4)]\n",
    "año_valido = año_actual if mes_actual in meses_validos else año_actual - 1\n",
    "\n",
    "# Función para obtener la etiqueta del mes\n",
    "def etiqueta_mes(fecha):\n",
    "    mes = fecha.month\n",
    "    año = fecha.year\n",
    "    \n",
    "    if mes == mes_actual and año == año_actual:\n",
    "        return f\"{hoy.strftime('%B')} {año_actual}\"\n",
    "    \n",
    "    if mes in meses_validos:\n",
    "        return f\"{fecha.strftime('%B')} {año}\"\n",
    "    \n",
    "    return 'Fuera de rango'\n",
    "\n",
    "# Aplicar la función al DataFrame\n",
    "df_merged['etiqueta_mes'] = df_merged['FECHA_REGISTRO_HH'].apply(etiqueta_mes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos del DataFrame a un archivo Excel\n",
    "#df_merged.to_excel(file_path_destino, index=False)\n",
    "\n",
    "# TODO sacar comentario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos un filtro para los documentos en bse a fehca_salida \n",
    "fecha_inicial = datetime(2024, 8, 1)\n",
    "fecha_final = datetime(2024, 8, 10)\n",
    "\n",
    "filtro_fecha_salida = (df_merged['FECHA_SALIDA'] >= fecha_inicial) & (df_merged['FECHA_SALIDA'] <= fecha_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparamos la exprotación a sheets\n",
    "#  es necesario convertir los timestamps a string, en formato yyyy-mm-dd hh:mm:ss\n",
    "# convertimos los timestamps a string, teniendo en cuenta que pueden haber NaTs\n",
    "\n",
    "df_merged = df_merged.applymap(\n",
    "    lambda x: x.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    if isinstance(x, (pd.Timestamp, datetime)) and not pd.isnull(x) else x\n",
    ")\n",
    "\n",
    "# reemplazamos NaNs con espccios vacíos\n",
    "df_merged= df_merged.applymap(lambda x: '' if pd.isnull(x) else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gs.oauth(credentials_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1xXVP33Zg4bzxH-xUvKZRxeTvhsRdlDDfzIXqc2ttHus',\n",
       " 'updatedRange': \"'Hoja 1'!A1:AG28960\",\n",
       " 'updatedRows': 28960,\n",
       " 'updatedColumns': 33,\n",
       " 'updatedCells': 955680}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exportamos a google sheets\n",
    "\n",
    "sh = gc.open('documentos_procesado')\n",
    "worksheet = sh.sheet1\n",
    "worksheet.update([df_merged.columns.values.tolist()] + df_merged.values.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
